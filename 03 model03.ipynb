{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELO 3 - ....\n",
    "\n",
    "# POR ACABAR !!!!!!!!!!\n",
    "\n",
    "#### use faa03 kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"data/data_train.csv\")\n",
    "df_test = pd.read_csv(\"data/data_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.6391\n",
      "Root Mean Squared Error: 0.639061006791933\n"
     ]
    }
   ],
   "source": [
    "from surprise import Dataset, Reader\n",
    "from surprise import SVD\n",
    "from surprise import accuracy\n",
    "import pandas as pd\n",
    "\n",
    "# Load your ratings data\n",
    "ratings_df = df_train\n",
    "\n",
    "# Define the format for Surprise (user, item, rating)\n",
    "reader = Reader(rating_scale=(1, 5))  # Adjust rating scale based on your data\n",
    "data = Dataset.load_from_df(ratings_df[['userId', 'movieId', 'rating']], reader)\n",
    "\n",
    "# Split the data into trainset and testset (optional)\n",
    "trainset = data.build_full_trainset()  # Use the full data for prediction\n",
    "testset = trainset.build_testset()  # Use the full testset (or a specific subset)\n",
    "\n",
    "# Initialize the SVD algorithm\n",
    "algo = SVD()\n",
    "\n",
    "# Train the model\n",
    "algo.fit(trainset)\n",
    "\n",
    "# Predict ratings for all combinations of users and movies in the testset\n",
    "predictions = algo.test(testset)\n",
    "\n",
    "# Optional: Evaluate the model (e.g., RMSE)\n",
    "rmse = accuracy.rmse(predictions)\n",
    "print(f'Root Mean Squared Error: {rmse}')\n",
    "\n",
    "# Create a dictionary of predictions\n",
    "all_predictions = {}\n",
    "for prediction in predictions:\n",
    "    user = prediction.uid\n",
    "    item = prediction.iid\n",
    "    predicted_rating = prediction.est\n",
    "    if user not in all_predictions:\n",
    "        all_predictions[user] = {}\n",
    "    all_predictions[user][item] = predicted_rating\n",
    "\n",
    "# Now `all_predictions` contains all predicted ratings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD on 8 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Fold 6  Fold 7  Fold 8  Mean    Std     \n",
      "RMSE (testset)    0.8620  0.8807  0.8678  0.8611  0.8636  0.8701  0.8727  0.8659  0.8680  0.0061  \n",
      "MAE (testset)     0.6650  0.6779  0.6653  0.6593  0.6619  0.6650  0.6669  0.6676  0.6661  0.0051  \n",
      "Fit time          0.45    0.44    0.43    0.42    0.42    0.42    0.42    0.42    0.43    0.01    \n",
      "Test time         0.03    0.10    0.03    0.03    0.03    0.08    0.03    0.03    0.04    0.03    \n",
      "Average RMSE: 0.8680\n",
      "Average MAE: 0.6661\n"
     ]
    }
   ],
   "source": [
    "from surprise import Dataset, Reader, SVD\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "# Load your ratings data\n",
    "ratings_df = pd.read_csv('data/ratings.csv')  # Ensure this is the correct path\n",
    "\n",
    "# Define the format for Surprise (user, item, rating)\n",
    "reader = Reader(rating_scale=(1, 5))  # Adjust rating scale based on your data\n",
    "data = Dataset.load_from_df(ratings_df[['userId', 'movieId', 'rating']], reader)\n",
    "\n",
    "# Initialize the SVD algorithm\n",
    "algo = SVD()\n",
    "\n",
    "# Perform 8-fold cross-validation\n",
    "cv_results = cross_validate(algo, data, cv=8, measures=['RMSE', 'MAE'], verbose=True)\n",
    "\n",
    "# Average results over the 8 folds\n",
    "print(f\"Average RMSE: {cv_results['test_rmse'].mean():.4f}\")\n",
    "print(f\"Average MAE: {cv_results['test_mae'].mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSE: 0.8643\n",
      "Best Hyperparameters: {'n_factors': 100, 'lr_all': 0.01, 'reg_all': 0.1}\n",
      "   userId  movieId  predicted_rating\n",
      "0       0        0          3.502572\n",
      "1       0        1          3.856956\n",
      "2       0        2          3.470802\n",
      "3       0        3          3.246449\n",
      "4       0        4          2.794946\n"
     ]
    }
   ],
   "source": [
    "from surprise import Dataset, Reader, SVD\n",
    "from surprise.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "ratings_df = df_train\n",
    "reader = Reader(rating_scale=(1, 5))  # Adjust rating scale if needed\n",
    "data = Dataset.load_from_df(ratings_df[['userId', 'movieId', 'rating']], reader)\n",
    "\n",
    "# Define hyperparameter grid for SVD\n",
    "param_grid = {\n",
    "    'n_factors': [50, 100, 150],        # Number of latent factors\n",
    "    'lr_all': [0.002, 0.005, 0.01],    # Learning rate\n",
    "    'reg_all': [0.02, 0.1, 0.2]        # Regularization term\n",
    "}\n",
    "\n",
    "# Perform 8-fold cross-validation for hyperparameter tuning\n",
    "gs = GridSearchCV(SVD, param_grid, measures=['rmse'], cv=8)\n",
    "gs.fit(data)\n",
    "\n",
    "# Get the best parameters and the corresponding RMSE\n",
    "print(f\"Best RMSE: {gs.best_score['rmse']:.4f}\")\n",
    "print(\"Best Hyperparameters:\", gs.best_params['rmse'])\n",
    "\n",
    "# Train the best model on the entire dataset\n",
    "best_algo = gs.best_estimator['rmse']\n",
    "trainset = data.build_full_trainset()\n",
    "best_algo.fit(trainset)\n",
    "\n",
    "# Predict all ratings\n",
    "all_user_ids = trainset.all_users()  # Internal user IDs\n",
    "all_item_ids = trainset.all_items()  # Internal item IDs\n",
    "\n",
    "# Generate predictions for all user-item pairs\n",
    "all_predictions = []\n",
    "for user in all_user_ids:\n",
    "    for item in all_item_ids:\n",
    "        all_predictions.append(best_algo.predict(user, item))\n",
    "\n",
    "# Convert predictions to a more readable format (optional)\n",
    "predictions_df = pd.DataFrame([{\n",
    "    'userId': pred.uid,\n",
    "    'movieId': pred.iid,\n",
    "    'predicted_rating': pred.est\n",
    "} for pred in all_predictions])\n",
    "\n",
    "# Display sample predictions\n",
    "print(predictions_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSE: 0.8571\n",
      "Best Hyperparameters: {'n_factors': 150, 'lr_all': 0.01, 'reg_all': 0.1}\n",
      "RMSE: 0.8592\n",
      "MAE:  0.6628\n",
      "   userId  movieId  true_rating  predicted_rating\n",
      "0     537   104218          3.5          3.923755\n",
      "1     393     4022          5.0          3.983535\n",
      "2     448     5309          2.0          2.644740\n",
      "3     510     3360          3.5          3.066725\n",
      "4     223     7541          3.5          3.065923\n"
     ]
    }
   ],
   "source": [
    "from surprise import Dataset, Reader, SVD\n",
    "from surprise.model_selection import train_test_split, GridSearchCV\n",
    "from surprise import accuracy\n",
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "ratings_df = pd.read_csv('data/ratings.csv')  # Adjust the path as necessary\n",
    "reader = Reader(rating_scale=(1, 5))  # Adjust rating scale if needed\n",
    "data = Dataset.load_from_df(ratings_df[['userId', 'movieId', 'rating']], reader)\n",
    "\n",
    "# Step 1: Perform grid search on the original Dataset object\n",
    "param_grid = {\n",
    "    'n_factors': [50, 100, 150],        # Number of latent factors\n",
    "    'lr_all': [0.002, 0.005, 0.01],    # Learning rate\n",
    "    'reg_all': [0.02, 0.1, 0.2]        # Regularization term\n",
    "}\n",
    "\n",
    "# Use the original Dataset for grid search\n",
    "gs = GridSearchCV(SVD, param_grid, measures=['rmse'], cv=8)\n",
    "gs.fit(data)  # Use Dataset, not Trainset\n",
    "\n",
    "# Step 2: Get the best parameters and retrain the model\n",
    "print(f\"Best RMSE: {gs.best_score['rmse']:.4f}\")\n",
    "print(\"Best Hyperparameters:\", gs.best_params['rmse'])\n",
    "best_algo = gs.best_estimator['rmse']\n",
    "\n",
    "# Step 3: Split data into train and test sets\n",
    "trainset, testset = train_test_split(data, test_size=0.2)  # 80% train, 20% test # MAS ASSIM ELE JA VIU OS DADOS !!!!!\n",
    "\n",
    "# Step 4: Fit the best model on the training set\n",
    "best_algo.fit(trainset)\n",
    "\n",
    "# Step 5: Evaluate on the test set\n",
    "predictions = best_algo.test(testset)\n",
    "\n",
    "# Step 6: Compute metrics on the test set\n",
    "rmse = accuracy.rmse(predictions)\n",
    "mae = accuracy.mae(predictions)\n",
    "\n",
    "# Optional: Save predictions to a DataFrame for analysis\n",
    "predictions_df = pd.DataFrame([{\n",
    "    'userId': pred.uid,\n",
    "    'movieId': pred.iid,\n",
    "    'true_rating': pred.r_ui,\n",
    "    'predicted_rating': pred.est\n",
    "} for pred in predictions])\n",
    "\n",
    "print(predictions_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FAA03",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
